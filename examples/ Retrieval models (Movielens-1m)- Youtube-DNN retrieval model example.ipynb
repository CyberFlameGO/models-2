{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e364b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea09b33",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Building Youtube-DNN Retrieval Model using Merlin Models\n",
    "\n",
    "## Overview\n",
    "\n",
    "[Merlin Models](https://github.com/NVIDIA-Merlin/models/) provided the necessary blocks to support a two-stage pipeline that connects an item retrieval model (extracts a subset of relevant items) to a ranking model (identifies the top-k items that are to be displayed to the user). For more information about the two-stage pipeline, you can check the example notebook [Retrieval models (ALI-CCP)- Two-Tower model example]**(add link when it is merged)**. \n",
    "\n",
    "[Youtube-DNN](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf) is a sophisticated two-stage recommender model that proposes novel architectures of the retrieval and the ranking models and trains them with custom training tasks. In this notebook, we are going to build, train and evaluate the retrieval achitecture. \n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Training and Evaluating [Google's Youtube-DNN retrieval model](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf) with only 3 commands.\n",
    "- Building a retrieval index from the trained model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935011ee",
   "metadata": {},
   "source": [
    "## Downloading and preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d77a97a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 22:40:12.496523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24570 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:65:00.0, compute capability: 8.6\n",
      "downloading ml-1m.zip: 5.93MB [00:01, 4.95MB/s]                                                                                                                                                  \n",
      "unzipping files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 39.67files/s]\n",
      "/retrieval/youtube_dnn/movielens.py:85: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users = pd.read_csv(\n",
      "/retrieval/youtube_dnn/movielens.py:92: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies = pd.read_csv(\n",
      "/retrieval/youtube_dnn/movielens.py:99: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings = pd.read_csv(\n",
      "INFO:movielens:starting ETL..\n",
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "INFO:movielens:saving the workflow..\n",
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from movielens import get_session_movielens\n",
    "MAX_LENGTH = 30\n",
    "train, valid = get_movielens(pvariant=\"ml-1m\", user_sessions=True, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e37832f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>day</th>\n",
       "      <th>movieId-list</th>\n",
       "      <th>timestamp-list</th>\n",
       "      <th>genres-list</th>\n",
       "      <th>gender-first</th>\n",
       "      <th>age-first</th>\n",
       "      <th>occupation-first</th>\n",
       "      <th>zipcode-first</th>\n",
       "      <th>movieId-count</th>\n",
       "      <th>movieId-list_truncated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>[2249, 2317, 1102, 1767, 395, 1230, 963, 1270,...</td>\n",
       "      <td>[3865, 3865, 3865, 3865, 3865, 3865, 3865, 386...</td>\n",
       "      <td>[16, 2, 1, 1, 3, 8, 4, 3, 8, 4, 7, 8, 5, 4, 8,...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>118</td>\n",
       "      <td>[3008, 1987, 639, 1955, 50, 2514, 128, 1038, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>[672, 558, 599, 1020, 661, 1620, 1583, 2374, 1...</td>\n",
       "      <td>[7742, 7742, 7742, 7742, 7742, 7742, 7742, 943...</td>\n",
       "      <td>[17, 8, 17, 8, 17, 4, 8, 17, 4, 2, 2, 14, 2, 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>[672, 558, 599, 1020, 661, 1620, 1583, 2374, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>[1459, 815, 518, 656, 512, 2709, 187, 106, 710...</td>\n",
       "      <td>[2076, 2076, 2076, 2076, 2076, 2076, 4011, 401...</td>\n",
       "      <td>[9, 4, 1, 2, 9, 4, 3, 8, 1, 13, 14, 4, 2, 4, 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>147</td>\n",
       "      <td>[121, 1267, 73, 231, 2494, 341, 972, 1808, 254...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>[2701, 2794, 3005, 3318, 2950, 2364, 786, 871,...</td>\n",
       "      <td>[15406, 15406, 15406, 15406, 15406, 15406, 532...</td>\n",
       "      <td>[2, 13, 4, 2, 1, 3, 9, 5, 4, 1, 2, 2, 3, 5, 1,...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>[2701, 2794, 3005, 3318, 2950, 2364, 786, 871,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>[856, 45, 143, 1212, 1482, 1031, 1153, 2148, 1...</td>\n",
       "      <td>[1050, 1050, 1050, 1050, 1050, 1050, 1050, 105...</td>\n",
       "      <td>[1, 7, 10, 2, 13, 2, 6, 11, 1, 13, 6, 1, 1, 11...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>[2248, 3097, 2845, 3246, 3054, 3195, 3247, 162...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  day                                       movieId-list  \\\n",
       "0       1  100  [2249, 2317, 1102, 1767, 395, 1230, 963, 1270,...   \n",
       "1       1  104  [672, 558, 599, 1020, 661, 1620, 1583, 2374, 1...   \n",
       "2       1  105  [1459, 815, 518, 656, 512, 2709, 187, 106, 710...   \n",
       "3       1  112  [2701, 2794, 3005, 3318, 2950, 2364, 786, 871,...   \n",
       "4       1  116  [856, 45, 143, 1212, 1482, 1031, 1153, 2148, 1...   \n",
       "\n",
       "                                      timestamp-list  \\\n",
       "0  [3865, 3865, 3865, 3865, 3865, 3865, 3865, 386...   \n",
       "1  [7742, 7742, 7742, 7742, 7742, 7742, 7742, 943...   \n",
       "2  [2076, 2076, 2076, 2076, 2076, 2076, 4011, 401...   \n",
       "3  [15406, 15406, 15406, 15406, 15406, 15406, 532...   \n",
       "4  [1050, 1050, 1050, 1050, 1050, 1050, 1050, 105...   \n",
       "\n",
       "                                         genres-list  gender-first  age-first  \\\n",
       "0  [16, 2, 1, 1, 3, 8, 4, 3, 8, 4, 7, 8, 5, 4, 8,...             1          5   \n",
       "1  [17, 8, 17, 8, 17, 4, 8, 17, 4, 2, 2, 14, 2, 2...             1          5   \n",
       "2  [9, 4, 1, 2, 9, 4, 3, 8, 1, 13, 14, 4, 2, 4, 2...             1          5   \n",
       "3  [2, 13, 4, 2, 1, 3, 9, 5, 4, 1, 2, 2, 3, 5, 1,...             1          5   \n",
       "4  [1, 7, 10, 2, 13, 2, 6, 11, 1, 13, 6, 1, 1, 11...             1          5   \n",
       "\n",
       "   occupation-first  zipcode-first  movieId-count  \\\n",
       "0                 2             11            118   \n",
       "1                 2             11             10   \n",
       "2                 2             11            147   \n",
       "3                 2             11             15   \n",
       "4                 2             11             51   \n",
       "\n",
       "                              movieId-list_truncated  \n",
       "0  [3008, 1987, 639, 1955, 50, 2514, 128, 1038, 7...  \n",
       "1  [672, 558, 599, 1020, 661, 1620, 1583, 2374, 1...  \n",
       "2  [121, 1267, 73, 231, 2494, 341, 972, 1808, 254...  \n",
       "3  [2701, 2794, 3005, 3318, 2950, 2364, 786, 871,...  \n",
       "4  [2248, 3097, 2845, 3246, 3054, 3195, 3247, 162...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d2701",
   "metadata": {},
   "source": [
    "## Train Youtube-DNN retrieval model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c5507",
   "metadata": {},
   "source": [
    "The candidate generation network proposed by [Youtube-DNN](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf) leverages the sequence of YouTube browsing history as well as other context features about the user. \n",
    "\n",
    "\n",
    "The model is inspired by the architecture of bag of word representation in NLP domain. In a nutshell, the sequence of `N-1` past events are averaged to create the user's interactions embeddings based on the event's type (`watch_vector`, `search_vector`), and then the model is trained to predict the next  video to be interacted with. Lastly, [sampled-softmax](http://arxiv.org/abs/1412.2007) loss is used to efficiently train over a large catalog of items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782271b4",
   "metadata": {},
   "source": [
    "<img src=\"images/YoutubeDNN.png\"  width=\"30%\">\n",
    "\n",
    "<a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\">Image Source: Youtube-DNN paper</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405026f6",
   "metadata": {},
   "source": [
    "We select a subset of features to use for training the retrieval model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24fb2c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = train.schema.select_by_name(['userId', 'movieId-list_truncated', 'gender-first', 'age-first','occupation-first', 'zipcode-first'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb12f4c9",
   "metadata": {},
   "source": [
    "We initalize the YoutubeDNNRetrieval model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b6dcf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import merlin.models.tf as mm\n",
    "from tensorflow.keras import regularizers\n",
    "model = mm.YoutubeDNNRetrievalModel(\n",
    "    schema=schema, \n",
    "    num_sampled=1000, \n",
    "    top_block=mm.MLPBlock([128, 64]),\n",
    "    max_seq_length=MAX_LENGTH\n",
    ")\n",
    "model.compile(optimizer=\"adam\", run_eagerly=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ffe40",
   "metadata": {},
   "source": [
    "Next, we train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "965ad589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 22:40:24.999533: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-03-22 22:40:26.610685: I tensorflow/stream_executor/cuda/cuda_blas.cc:1792] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f70858eb820>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:merlin_models:The sampler PopularityBasedSampler returned no samples for this batch.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f70858eb820>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f70858eb820>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "84/84 [==============================] - ETA: 0s - recall_at_10: 0.0089 - mrr_at_10: 0.0029 - ndcg_10: 0.0042 - map_at_10: 0.0029 - precision_at_10: 8.8897e-04 - loss: 5.3931 - regularization_loss: 0.0000e+00 - total_loss: 5.3931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 22:40:36.004959: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: cond/then/_0/cond/cond/branch_executed/_154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 10s 41ms/step - recall_at_10: 0.0089 - mrr_at_10: 0.0029 - ndcg_10: 0.0042 - map_at_10: 0.0029 - precision_at_10: 8.8897e-04 - loss: 5.4564 - regularization_loss: 0.0000e+00 - total_loss: 5.4564 - val_recall_at_10: 0.0083 - val_mrr_at_10: 0.0022 - val_ndcg_10: 0.0036 - val_map_at_10: 0.0022 - val_precision_at_10: 8.3276e-04 - val_loss: 4.8658 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.8658\n",
      "Epoch 2/5\n",
      "84/84 [==============================] - 2s 18ms/step - recall_at_10: 0.0109 - mrr_at_10: 0.0034 - ndcg_10: 0.0051 - map_at_10: 0.0034 - precision_at_10: 0.0011 - loss: 5.2993 - regularization_loss: 0.0000e+00 - total_loss: 5.2993 - val_recall_at_10: 0.0104 - val_mrr_at_10: 0.0029 - val_ndcg_10: 0.0047 - val_map_at_10: 0.0029 - val_precision_at_10: 0.0010 - val_loss: 4.8616 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.8616\n",
      "Epoch 3/5\n",
      "84/84 [==============================] - 2s 18ms/step - recall_at_10: 0.0131 - mrr_at_10: 0.0039 - ndcg_10: 0.0061 - map_at_10: 0.0039 - precision_at_10: 0.0013 - loss: 5.5392 - regularization_loss: 0.0000e+00 - total_loss: 5.5392 - val_recall_at_10: 0.0104 - val_mrr_at_10: 0.0028 - val_ndcg_10: 0.0046 - val_map_at_10: 0.0028 - val_precision_at_10: 0.0010 - val_loss: 4.8587 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.8587\n",
      "Epoch 4/5\n",
      "84/84 [==============================] - 2s 18ms/step - recall_at_10: 0.0144 - mrr_at_10: 0.0043 - ndcg_10: 0.0066 - map_at_10: 0.0043 - precision_at_10: 0.0014 - loss: 5.1753 - regularization_loss: 0.0000e+00 - total_loss: 5.1753 - val_recall_at_10: 0.0097 - val_mrr_at_10: 0.0022 - val_ndcg_10: 0.0038 - val_map_at_10: 0.0022 - val_precision_at_10: 9.7155e-04 - val_loss: 8.9167 - val_regularization_loss: 0.0000e+00 - val_total_loss: 8.9167\n",
      "Epoch 5/5\n",
      "84/84 [==============================] - 2s 18ms/step - recall_at_10: 0.0148 - mrr_at_10: 0.0044 - ndcg_10: 0.0068 - map_at_10: 0.0044 - precision_at_10: 0.0015 - loss: 5.4462 - regularization_loss: 0.0000e+00 - total_loss: 5.4462 - val_recall_at_10: 0.0076 - val_mrr_at_10: 0.0019 - val_ndcg_10: 0.0032 - val_map_at_10: 0.0019 - val_precision_at_10: 7.6336e-04 - val_loss: 4.8441 - val_regularization_loss: 0.0000e+00 - val_total_loss: 4.8441\n"
     ]
    }
   ],
   "source": [
    "losses = model.fit(train,validation_data=valid, batch_size=256, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ebf0d5",
   "metadata": {},
   "source": [
    "We evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e7f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 13ms/step - recall_at_10: 0.0062 - mrr_at_10: 0.0016 - ndcg_10: 0.0027 - map_at_10: 0.0016 - precision_at_10: 6.2457e-04 - loss: 8.2522 - regularization_loss: 0.0000e+00 - total_loss: 8.2522        \n"
     ]
    }
   ],
   "source": [
    "history = model.evaluate(valid, batch_size=64, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee1cfcf",
   "metadata": {},
   "source": [
    "## From model to top-k recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795bc9b3",
   "metadata": {},
   "source": [
    "After training, the neural network is learned high dimensional embeddings about each movie which are organized in a fixed vocabulary. The user representation vector `u` the pre-computed embeddings of videos `V` are then fed to the Neirest Neighbor Index to retrieve the top-N videos to feed to the ranking stage for building the final list of recommendation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2533a4",
   "metadata": {},
   "source": [
    "**IN progress** \n",
    "\n",
    "Need to implement the option of exporting item/user towers from YoutubeDNN retrieval model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "411fda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "# pre_embbedings = model.first['sparse'][0][0]['categorical'].embedding_tables['movieId-list_seq']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
