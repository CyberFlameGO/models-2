{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8afc8",
   "metadata": {},
   "source": [
    "## Advanced: Define your own architecture\n",
    "\n",
    "### Overview: \n",
    "In [explore-different-models](https://github.com/NVIDIA-Merlin/models/blob/main/examples/Exploring-different-models.ipynb) , we conduct \n",
    "a benchmark of various ranking models provided by the high-level Merlin Models API. The library also includes the standard components of deep learning that will let recsys practioners and researchers to define custom models, train and export them for inference.  \n",
    "\n",
    "\n",
    "In this example, we will combine pre-existing blocks and demonstrate how to create the [DLRM](https://arxiv.org/abs/1906.00091) architecture.\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "- Get familiarized with Merlin Models building blocks\n",
    "- Define a model architecture from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a35e8",
   "metadata": {},
   "source": [
    "### Introduction to Merlin-models core building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e27171",
   "metadata": {},
   "source": [
    "The [Block](https://nvidia-merlin.github.io/models/review/pr-294/generated/merlin.models.tf.Block.html#merlin.models.tf.Block) is the core abstraction in Merlin Models and is the class from which all blocks inherit.\n",
    "The class extends the [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) base class and implements a number of properties that simplify the creation of custom blocks/models. These properties include the `Schema` object for determining the embedding dimensions, input shapes, and output shapes. Additionally, `Block` has a `BlockContext` to store/retrieve public variables and share them with other blocks in the same model as additional meta-data. \n",
    "\n",
    "Before deep-diving into the definition of the DLRM architecture, let's start by listing the core components you need to know to define a model from scratch:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f19621",
   "metadata": {},
   "source": [
    "#### Features Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d708f",
   "metadata": {},
   "source": [
    "They include input blocks to process various inputs based on their types and shapes. We support three main Blocks: \n",
    "- `EmbeddingFeatures`: Input block for embedding-lookups for categorical features.\n",
    "- `SequenceEmbeddingFeatures`: Input block for embedding-lookups for sequential categorical features (3D tensors).\n",
    "- `ContinuousFeatures`: Input block for continuous features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fc3d5",
   "metadata": {},
   "source": [
    "#### Transformations Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe4840",
   "metadata": {},
   "source": [
    "They include various operators commonly used to transform tensors in various parts of the model, such as: \n",
    "\n",
    "- `AsDenseFeatures`: It takes a dictionary of raw input tensors and transforms the sparse ones into dense tensors.\n",
    "- `L2Norm`: It takes a single or a dictionary of hidden tensors and applies an L2-normalization along a given axis. \n",
    "- `LogitsTemperatureScaler`: It scales the output tensor of predicted logits to lower the model's confidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f80c8b",
   "metadata": {},
   "source": [
    "#### Aggregations Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084beb51",
   "metadata": {},
   "source": [
    "They inlude common aggregation ops to combine multiple tenors, such as: \n",
    "- `ConcatFeatures`: Concatenate dictionary of tensors along a given dimension.\n",
    "- `StackFeatures`: Stack dictionary of tensors along a given dimension.\n",
    "- `CosineSimilarity`: Calculate the cosine similarity between two tensors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbbb7b2",
   "metadata": {},
   "source": [
    "#### Connects Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea7afa5",
   "metadata": {},
   "source": [
    "The base class `Block` implements different connects methods that control how to link a given block to other blocks: \n",
    "\n",
    "- `connect`: Connect the block to other blocks sequentially. The output is a tensor returned by the last block. \n",
    "- `connect_branch`: Link the block to other blocks in parallel. The output is a dictionary containing the output tensor of each block.\n",
    "- `connect_with_shortcut`: Connect the block to other blocks sequentially and apply a skip connection with the block's output. \n",
    "- `connect_with_residual`: Connect the block to other blocks sequentially and apply a residual sum with the block's output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4366b",
   "metadata": {},
   "source": [
    "#### Prediction Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddb306a",
   "metadata": {},
   "source": [
    "Merlin Models introduces the `PredictionTask` layer that defines the necessary blocks and transformation ops to compute the final prediction scores. It also provides the default loss and metrics related to the given prediction task.\\\n",
    "We support the core tasks:  `BinaryClassificationTask`, `MultiClassClassificationTask`, and`RegressionTask`. As well as RecSys specific tasks: `NextItemPredictionTask`, and `ItemRetrievalTask`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e2ac1",
   "metadata": {},
   "source": [
    "### Implement the DLRM model with Movielens-1M data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba30a25",
   "metadata": {},
   "source": [
    "Now that we have introduced the core blocks of Merlin Models, let's take a look at how we can combine them to define the DLRM architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52eb41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 17:59:16.085354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24570 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:65:00.0, compute capability: 8.6\n",
      "/nvtabular/nvtabular/graph.py:23: FutureWarning: The `nvtabular.graph` module has moved to `merlin.dag`. Support for importing from `nvtabular.graph` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.dag`.\n",
      "  warnings.warn(\n",
      "/nvtabular/nvtabular/io.py:23: FutureWarning: The `nvtabular.io` module has moved to `merlin.io`. Support for importing from `nvtabular.io` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.io`.\n",
      "  warnings.warn(\n",
      "/nvtabular/nvtabular/utils.py:23: FutureWarning: The `nvtabular.utils` module has moved to `merlin.core.utils`. Support for importing from `nvtabular.utils` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.core.utils`.\n",
      "  warnings.warn(\n",
      "/nvtabular/nvtabular/dispatch.py:23: FutureWarning: The `nvtabular.dispatch` module has moved to `merlin.core.dispatch`. Support for importing from `nvtabular.dispatch` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.core.dispatch`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import merlin.models.tf as mm\n",
    "\n",
    "from merlin.models.data.movielens import get_movielens\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a9ea8f",
   "metadata": {},
   "source": [
    "We will use the utils function to download, extract and preprocess the MovieLens 1M  dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f77776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading ml-1m.zip: 5.93MB [00:00, 6.11MB/s]                                                                                                                                              \n",
      "unzipping files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 51.04files/s]\n",
      "/models/merlin/models/data/movielens.py:298: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  users = pd.read_csv(\n",
      "/models/merlin/models/data/movielens.py:303: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings = pd.read_csv(\n",
      "/models/merlin/models/data/movielens.py:308: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movies = pd.read_csv(\n",
      "INFO:merlin.models.data.movielens:starting ETL..\n",
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "INFO:merlin.models.data.movielens:saving the workflow..\n",
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train, valid = get_movielens(variant=\"ml-1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2a472b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>TE_age_rating</th>\n",
       "      <th>TE_gender_rating</th>\n",
       "      <th>TE_occupation_rating</th>\n",
       "      <th>TE_zipcode_rating</th>\n",
       "      <th>TE_movieId_rating</th>\n",
       "      <th>TE_userId_rating</th>\n",
       "      <th>rating_binary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>[12, 10, 1, 13]</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1203</td>\n",
       "      <td>0.211872</td>\n",
       "      <td>0.951709</td>\n",
       "      <td>0.331306</td>\n",
       "      <td>0.596845</td>\n",
       "      <td>0.711920</td>\n",
       "      <td>0.640945</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5326</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>[1, 9]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "      <td>0.796352</td>\n",
       "      <td>0.013199</td>\n",
       "      <td>0.667063</td>\n",
       "      <td>0.595427</td>\n",
       "      <td>0.755418</td>\n",
       "      <td>0.610061</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>967</td>\n",
       "      <td>970</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>159</td>\n",
       "      <td>0.150914</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.433342</td>\n",
       "      <td>0.482693</td>\n",
       "      <td>0.746300</td>\n",
       "      <td>0.539280</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>338</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>[2, 11]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>0.151640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.326860</td>\n",
       "      <td>0.664413</td>\n",
       "      <td>0.889771</td>\n",
       "      <td>0.713829</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592</td>\n",
       "      <td>1013</td>\n",
       "      <td>1009</td>\n",
       "      <td>[3, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.150703</td>\n",
       "      <td>0.013199</td>\n",
       "      <td>0.330231</td>\n",
       "      <td>0.598137</td>\n",
       "      <td>0.391695</td>\n",
       "      <td>0.558516</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  title           genres  gender  age  occupation  zipcode  \\\n",
       "0    1221       92     92  [12, 10, 1, 13]       2    7           2     1203   \n",
       "1    5326       28     28           [1, 9]       1    5          11       56   \n",
       "2      32      967    970           [1, 2]       1    1           8      159   \n",
       "3     338      143    143          [2, 11]       1    1           1       79   \n",
       "4     592     1013   1009           [3, 1]       1    1           1       13   \n",
       "\n",
       "   TE_age_rating  TE_gender_rating  TE_occupation_rating  TE_zipcode_rating  \\\n",
       "0       0.211872          0.951709              0.331306           0.596845   \n",
       "1       0.796352          0.013199              0.667063           0.595427   \n",
       "2       0.150914          0.013160              0.433342           0.482693   \n",
       "3       0.151640          0.000000              0.326860           0.664413   \n",
       "4       0.150703          0.013199              0.330231           0.598137   \n",
       "\n",
       "   TE_movieId_rating  TE_userId_rating  rating_binary  rating  \n",
       "0           0.711920          0.640945              1     4.0  \n",
       "1           0.755418          0.610061              1     4.0  \n",
       "2           0.746300          0.539280              1     4.0  \n",
       "3           0.889771          0.713829              1     5.0  \n",
       "4           0.391695          0.558516              0     2.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36133e64",
   "metadata": {},
   "source": [
    "We take the first batch of input tensors and use it to check the outputs of each building block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77303380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['genres', 'userId', 'movieId', 'title', 'gender', 'age', 'occupation', 'zipcode', 'TE_age_rating', 'TE_gender_rating', 'TE_occupation_rating', 'TE_zipcode_rating', 'TE_movieId_rating', 'TE_userId_rating'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from merlin.models.tf.dataset import BatchedDataset\n",
    "batch = next(iter(BatchedDataset(valid, batch_size=4, shuffle=False)))[0]\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3a6a9",
   "metadata": {},
   "source": [
    "#### Define the inputs block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c0a862",
   "metadata": {},
   "source": [
    "For the sake of simplicity, let's create a schema with a subset of the following continuous and categorical features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e139fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_schema = train.schema.select_by_name(['userId', 'movieId', 'title', 'gender', 'TE_zipcode_rating', 'TE_movieId_rating', 'rating_binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeeeb14",
   "metadata": {},
   "source": [
    "We define the continuous layer based on the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "478dc863",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_block = mm.ContinuousFeatures.from_schema(sub_schema, tags=Tags.CONTINUOUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4cd2f9",
   "metadata": {},
   "source": [
    "We visualize the output tensor of the continuous block using data of the first `batch`: it returns the raw tensors of continuous features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70704ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TE_zipcode_rating': <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       " array([[0.59684473],\n",
       "        [0.5954274 ],\n",
       "        [0.48269314],\n",
       "        [0.6644129 ]], dtype=float32)>,\n",
       " 'TE_movieId_rating': <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       " array([[0.7119201 ],\n",
       "        [0.7554184 ],\n",
       "        [0.7463003 ],\n",
       "        [0.88977146]], dtype=float32)>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_block(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dea2f1",
   "metadata": {},
   "source": [
    "We connect the continuous block to an `MLPBlock` so as to project them in a higher dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b180e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 17:59:52.609977: I tensorflow/stream_executor/cuda/cuda_blas.cc:1792] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_continuous_block = continuous_block.connect(mm.MLPBlock([64]))\n",
    "deep_continuous_block(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf48219",
   "metadata": {},
   "source": [
    "We define the categorical embedding block based on the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f70c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_block = mm.EmbeddingFeatures.from_schema(sub_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ce17a",
   "metadata": {},
   "source": [
    "We visualize the output tensor of the categorical block using data of the first `batch`: it returns the embeddings tensors of categorical features with a default dimension of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a46d7950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['userId', 'movieId', 'title', 'gender']), TensorShape([4, 64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embedding_block(batch)\n",
    "embeddings.keys(), embeddings['userId'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d8964",
   "metadata": {},
   "source": [
    "Let's store the continuous and categorical representations in a single dictionary using `ParallelBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba282a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shapes of DLRM input block:\n",
      "\tuserId : (4, 64)\n",
      "\tmovieId : (4, 64)\n",
      "\ttitle : (4, 64)\n",
      "\tgender : (4, 64)\n",
      "\tcontinuous : (4, 64)\n"
     ]
    }
   ],
   "source": [
    "dlrm_input_block = mm.ParallelBlock({\"embeddings\": embedding_block, \"continuous\": deep_continuous_block})\n",
    "print(\"Output shapes of DLRM input block:\")\n",
    "for key, val in dlrm_input_block(batch).items(): \n",
    "    print(\"\\t%s : %s\" %(key, val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443125e9",
   "metadata": {},
   "source": [
    "#### Define the interaction block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d13089",
   "metadata": {},
   "source": [
    "Now that we have a vector representation of each input feature, we will create the DLRM interaction block. It consists of three operations: \n",
    "- Apply a dot product between all continuous and categorical features to learn pairwise interactions. \n",
    "- Concat the resulting pairwise interaction with the deep representation of conitnuous features (skip-connection). \n",
    "- Apply an `MLPBlock` with a series of layers on the concatenated tensor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76859d73",
   "metadata": {},
   "source": [
    "First, we will use `connect_with_shortcut` to create the two first operations of DLRM interaction block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67f84a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.tf.blocks.dlrm import DotProductInteractionBlock\n",
    "dlrm_interaction = dlrm_input_block.connect_with_shortcut(\n",
    "    DotProductInteractionBlock(), \n",
    "    shortcut_filter=mm.Filter(\"continuous\"), \n",
    "    aggregation=\"concat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8df022",
   "metadata": {},
   "source": [
    "The following diagram visualize the ops of `dlrm_interaction`\n",
    "\n",
    "<img src=\"./images/residual_interaction.png\"  width=\"30%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9d552f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2080), dtype=float32, numpy=\n",
       "array([[ 0.        ,  0.        ,  0.        , ..., -0.074633  ,\n",
       "         0.00500197, -0.00703713],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.01555906,\n",
       "         0.01974952, -0.00702182],\n",
       "       [ 0.        ,  0.        ,  0.        , ..., -0.01452127,\n",
       "        -0.01577961,  0.00637832],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.00858589,\n",
       "        -0.0304167 , -0.03837536]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlrm_interaction(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8675b85",
   "metadata": {},
   "source": [
    "Then, we project the learned interaction using a series of dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c4196c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 512), dtype=float32, numpy=\n",
       "array([[0.        , 0.02887131, 0.03546177, ..., 0.        , 0.0269528 ,\n",
       "        0.00247553],\n",
       "       [0.        , 0.01354357, 0.03168381, ..., 0.00770783, 0.01776741,\n",
       "        0.        ],\n",
       "       [0.        , 0.01418068, 0.0157815 , ..., 0.00588702, 0.0095684 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.02814342, 0.0249888 , ..., 0.        , 0.02689105,\n",
       "        0.00350342]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_dlrm_interaction = dlrm_interaction.connect(mm.MLPBlock([64, 128, 512]))\n",
    "deep_dlrm_interaction(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7e6ad",
   "metadata": {},
   "source": [
    "#### Define the Prediction block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d9ebf",
   "metadata": {},
   "source": [
    "At this stage, we have created the DLRM block that takes as input a dictionary of categorical and continuous tensors and returns the interaction representation vector of shape `512`. The next step is to use this hidden representation to conduct a given prediction task. In our case, we will use the label `rating_binary` and the objective is: to predict if a user `A` will give a high rating to a movie `B` or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d339819",
   "metadata": {},
   "source": [
    "We will use the `BinaryClassificationTask` and evaluate the performances using `auc` metric. We will also use `LogitsTemperatureScaler` as a pre-transformation Op that scales the logits returned by the task before computing the loss and metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d83fa353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.tf.blocks.core.transformations import LogitsTemperatureScaler\n",
    "binary_task = mm.BinaryClassificationTask(\n",
    "    target_name=sub_schema.select_by_tag(Tags.TARGET).column_names[0],\n",
    "    metrics=[tf.keras.metrics.AUC], \n",
    "    pre=LogitsTemperatureScaler(temperature=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15589f9",
   "metadata": {},
   "source": [
    "#### Define, train and evaluate the final DLRM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759fd914",
   "metadata": {},
   "source": [
    "We connect the `deep_dlrm_interaction` to the `binary_task` and the method will automatically  generate the `Model` class for us.\n",
    "We note that the `Model` inherits from [tf.keras.Model](https://keras.io/api/models/model/) class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f939bf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merlin.models.tf.models.base.Model"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deep_dlrm_interaction.connect(binary_task)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8880876c",
   "metadata": {},
   "source": [
    "We train the model using built-in Keras `fit` method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a723cc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 17:59:53.392264: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding_features/userId:0', 'embedding_features/movieId:0', 'embedding_features/title:0', 'embedding_features/gender:0', 'parallel_block/userId:0', 'parallel_block/movieId:0', 'parallel_block/title:0', 'parallel_block/gender:0', 'sequential_block_7/userId:0', 'sequential_block_7/movieId:0', 'sequential_block_7/title:0', 'sequential_block_7/gender:0', 'sequential_block_9/userId:0', 'sequential_block_9/movieId:0', 'sequential_block_9/title:0', 'sequential_block_9/gender:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding_features/userId:0', 'embedding_features/movieId:0', 'embedding_features/title:0', 'embedding_features/gender:0', 'parallel_block/userId:0', 'parallel_block/movieId:0', 'parallel_block/title:0', 'parallel_block/gender:0', 'sequential_block_7/userId:0', 'sequential_block_7/movieId:0', 'sequential_block_7/title:0', 'sequential_block_7/gender:0', 'sequential_block_9/userId:0', 'sequential_block_9/movieId:0', 'sequential_block_9/title:0', 'sequential_block_9/gender:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding_features/userId:0', 'embedding_features/movieId:0', 'embedding_features/title:0', 'embedding_features/gender:0', 'parallel_block/userId:0', 'parallel_block/movieId:0', 'parallel_block/title:0', 'parallel_block/gender:0', 'sequential_block_7/userId:0', 'sequential_block_7/movieId:0', 'sequential_block_7/title:0', 'sequential_block_7/gender:0', 'sequential_block_9/userId:0', 'sequential_block_9/movieId:0', 'sequential_block_9/title:0', 'sequential_block_9/gender:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding_features/userId:0', 'embedding_features/movieId:0', 'embedding_features/title:0', 'embedding_features/gender:0', 'parallel_block/userId:0', 'parallel_block/movieId:0', 'parallel_block/title:0', 'parallel_block/gender:0', 'sequential_block_7/userId:0', 'sequential_block_7/movieId:0', 'sequential_block_7/title:0', 'sequential_block_7/gender:0', 'sequential_block_9/userId:0', 'sequential_block_9/movieId:0', 'sequential_block_9/title:0', 'sequential_block_9/gender:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 12s 12ms/step - rating_binary/binary_classification_task/auc: 0.6805 - loss: 0.6571 - regularization_loss: 0.0000e+00 - total_loss: 0.6571\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 10s 12ms/step - rating_binary/binary_classification_task/auc: 0.7262 - loss: 0.6381 - regularization_loss: 0.0000e+00 - total_loss: 0.6381\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 10s 12ms/step - rating_binary/binary_classification_task/auc: 0.7260 - loss: 0.6347 - regularization_loss: 0.0000e+00 - total_loss: 0.6347\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 11s 12ms/step - rating_binary/binary_classification_task/auc: 0.7249 - loss: 0.6324 - regularization_loss: 0.0000e+00 - total_loss: 0.6324\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 10s 12ms/step - rating_binary/binary_classification_task/auc: 0.7255 - loss: 0.6303 - regularization_loss: 0.0000e+00 - total_loss: 0.6303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79dec5e730>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\")\n",
    "model.fit(train, batch_size=1024, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01a643",
   "metadata": {},
   "source": [
    "- We get the evaluation scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e2afe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 18:00:47.183297: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: cond/then/_0/cond/cond/branch_executed/_128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 3s 8ms/step - rating_binary/binary_classification_task/auc: 0.7397 - loss: 2.7229 - regularization_loss: 0.0000e+00 - total_loss: 2.7229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rating_binary/binary_classification_task/auc': 0.7396634817123413,\n",
       " 'loss': 2.2757997512817383,\n",
       " 'regularization_loss': 0.0,\n",
       " 'total_loss': 2.2757997512817383}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid, batch_size=1024, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a45be",
   "metadata": {},
   "source": [
    "- We save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf607a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) TE_age_rating, TE_gender_rating, TE_movieId_rating, TE_occupation_rating, TE_userId_rating, TE_zipcode_rating, movieId, userId with unsupported characters which will be renamed to te_age_rating, te_gender_rating, te_movieid_rating, te_occupation_rating, te_userid_rating, te_zipcode_rating, movieid, userid in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as sequential_block_9_layer_call_fn, sequential_block_9_layer_call_and_return_conditional_losses, binary_classification_task_layer_call_fn, binary_classification_task_layer_call_and_return_conditional_losses, sequential_block_9_layer_call_fn while saving (showing 5 of 155). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: custom_dlrm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: custom_dlrm/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"custom_dlrm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f535e",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "\n",
    "#TODO\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
