{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86878b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca94cd8",
   "metadata": {},
   "source": [
    "## Build your own DLRM model \n",
    "\n",
    "#TODO:  Add general introduction + Add references to DLRM paper and merlin example notebook \n",
    "\n",
    "### Learning objectives\n",
    "- Getting familiarized with Merlin models building blocks\n",
    "- Building a model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405dd82",
   "metadata": {},
   "source": [
    "### Introduction to Merlin-models core building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e51a13",
   "metadata": {},
   "source": [
    "The [Block](https://nvidia-merlin.github.io/models/review/pr-294/generated/merlin.models.tf.Block.html#merlin.models.tf.Block) is the core abstraction in Merlin models and is the class from which all blocks inherit.\n",
    "The class extends the [tf.keras.layers.Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) base class and implements a number of properties that simplify the creation of custom blocks/models. These properties include the `Schema` object for determining the embedding dimensions, input shapes, and output shapes. Additionally, `Block` has a `BlockContext` to store/retrieve public variables and share them with other blocks in the same model as additional meta-data. \n",
    "\n",
    "\n",
    "\n",
    "For this example, we will combine pre-existing blocks and demonstrate how to create the DLRM architecture. So let's start by listing the core Blocks you need to know to build a model from scratch: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e929ae4",
   "metadata": {},
   "source": [
    "#### Features Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f0ff34",
   "metadata": {},
   "source": [
    "They include input blocks to process various inputs based on their types and shapes. We support three main Blocks: \n",
    "- `EmbeddingFeatures`: Input block for embedding-lookups for categorical features.\n",
    "- `SequenceEmbeddingFeatures`: Input block for embedding-lookups for sequential categorical features (3D tensors).\n",
    "- `ContinuousFeatures`: Input block for continuous features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37a2d6",
   "metadata": {},
   "source": [
    "#### Transformations Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9bca0b",
   "metadata": {},
   "source": [
    "They include various operators commonly used to transform tensors in various parts of the model, such as: \n",
    "\n",
    "- `AsDenseFeatures`: It takes a dictionary of raw input tensors and transforms the sparse ones into dense tensors.\n",
    "- `L2Norm`: It takes a single or a dictionary of hidden tensors and applies an L2-normalization along a given axis. \n",
    "- `LogitsTemperatureScaler`: It scales the output tensor of predicted logits to lower the model's confidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a31f9",
   "metadata": {},
   "source": [
    "#### Aggregations Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e4230",
   "metadata": {},
   "source": [
    "They inlude common aggregation ops to combine multiple tenors, such as: \n",
    "- `ConcatFeatures`:\n",
    "- `StackFeatures`:\n",
    "- `CosineSimilarity`: \n",
    "\n",
    "#TODO add description of each block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53333bc2",
   "metadata": {},
   "source": [
    "#### Combinators Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1fc6f",
   "metadata": {},
   "source": [
    "They include the base ops to combine different blocks together: \n",
    "- `SequentialBlock`\n",
    "- `ParallelBlock`\n",
    "- `ResidualBlock`\n",
    "\n",
    "#TODO add description of each block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038ff5cf",
   "metadata": {},
   "source": [
    "### Prediction Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66d6305",
   "metadata": {},
   "source": [
    "They include the common prediction tasks and are responsible of building the final prediction scores, computing the loss and evaluation metrics: \n",
    "\n",
    "- `BinaryClassificationTask`\n",
    "- `MultiClassClassificationTask`\n",
    "- `RegressionTask`\n",
    "\n",
    "#TODO add description of each block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61e43c",
   "metadata": {},
   "source": [
    "### Build the DLRM model with Movielens-1M data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b9c2f8",
   "metadata": {},
   "source": [
    "Now that we have iterated introduced the core blocks of Merlin models, let's take a look at how we can combine them to build the DLRM architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "676b62f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 15:35:07.136315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24570 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import merlin.models.tf as mm\n",
    "\n",
    "from merlin.models.data.movielens import get_movielens\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33822820",
   "metadata": {},
   "source": [
    "We will use the utils function to download, extract and preprocess the MovieLens 1M  dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0befe4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train, valid = get_movielens(variant=\"ml-1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa4c465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>TE_age_rating</th>\n",
       "      <th>TE_gender_rating</th>\n",
       "      <th>TE_occupation_rating</th>\n",
       "      <th>TE_zipcode_rating</th>\n",
       "      <th>TE_movieId_rating</th>\n",
       "      <th>TE_userId_rating</th>\n",
       "      <th>rating_binary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2181</td>\n",
       "      <td>935</td>\n",
       "      <td>932</td>\n",
       "      <td>[3, 5]</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1770</td>\n",
       "      <td>0.982804</td>\n",
       "      <td>0.989014</td>\n",
       "      <td>0.640637</td>\n",
       "      <td>0.469049</td>\n",
       "      <td>0.440049</td>\n",
       "      <td>0.537162</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>147</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[3, 7, 6, 5, 11]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>282</td>\n",
       "      <td>0.497828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425216</td>\n",
       "      <td>0.775113</td>\n",
       "      <td>0.811054</td>\n",
       "      <td>0.809315</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2719</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>[8, 4]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>784</td>\n",
       "      <td>0.484754</td>\n",
       "      <td>0.943272</td>\n",
       "      <td>0.436012</td>\n",
       "      <td>0.671168</td>\n",
       "      <td>0.986661</td>\n",
       "      <td>0.781915</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>956</td>\n",
       "      <td>1270</td>\n",
       "      <td>1269</td>\n",
       "      <td>[18]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>352</td>\n",
       "      <td>0.140412</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>0.326065</td>\n",
       "      <td>0.668503</td>\n",
       "      <td>0.850387</td>\n",
       "      <td>0.665899</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "      <td>[9]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>523</td>\n",
       "      <td>0.497828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.330956</td>\n",
       "      <td>0.519841</td>\n",
       "      <td>0.503531</td>\n",
       "      <td>0.581438</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  title            genres  gender  age  occupation  zipcode  \\\n",
       "0    2181      935    932            [3, 5]       2    6          11     1770   \n",
       "1     147        4      4  [3, 7, 6, 5, 11]       1    4           4      282   \n",
       "2    2719       40     40            [8, 4]       2    4           4      784   \n",
       "3     956     1270   1269              [18]       1    1           2      352   \n",
       "4     314      746    746               [9]       1    4          15      523   \n",
       "\n",
       "   TE_age_rating  TE_gender_rating  TE_occupation_rating  TE_zipcode_rating  \\\n",
       "0       0.982804          0.989014              0.640637           0.469049   \n",
       "1       0.497828          0.000000              0.425216           0.775113   \n",
       "2       0.484754          0.943272              0.436012           0.671168   \n",
       "3       0.140412          0.014632              0.326065           0.668503   \n",
       "4       0.497828          0.000000              0.330956           0.519841   \n",
       "\n",
       "   TE_movieId_rating  TE_userId_rating  rating_binary  rating  \n",
       "0           0.440049          0.537162              0     3.0  \n",
       "1           0.811054          0.809315              0     3.0  \n",
       "2           0.986661          0.781915              1     5.0  \n",
       "3           0.850387          0.665899              0     3.0  \n",
       "4           0.503531          0.581438              0     1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6d570e",
   "metadata": {},
   "source": [
    "We take the first batch of input tensors to check the outputs of each building block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f4d0c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['genres', 'userId', 'movieId', 'title', 'gender', 'age', 'occupation', 'zipcode', 'TE_age_rating', 'TE_gender_rating', 'TE_occupation_rating', 'TE_zipcode_rating', 'TE_movieId_rating', 'TE_userId_rating'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from merlin.models.tf.dataset import BatchedDataset\n",
    "batch = next(iter(BatchedDataset(valid, batch_size=4, shuffle=False)))[0]\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0001899",
   "metadata": {},
   "source": [
    "### Build the inputs block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ad20e",
   "metadata": {},
   "source": [
    "For the sake of simplicity, let's create a schema with a subset of the following continuous and categorical features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b7691b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_schema = train.schema.select_by_name(['userId', 'movieId', 'title', 'gender', 'TE_zipcode_rating', 'TE_movieId_rating', 'rating_binary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9413d260",
   "metadata": {},
   "source": [
    "We define the continous layer based on the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c3c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_block = mm.ContinuousFeatures.from_schema(sub_schema, tags=Tags.CONTINUOUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665ab10",
   "metadata": {},
   "source": [
    "We visualize the output tensor of the continuous block using data of the first `batch`: it returns the raw tensors of continuous features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ffe3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TE_zipcode_rating': <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       " array([[0.46904874],\n",
       "        [0.7751127 ],\n",
       "        [0.67116815],\n",
       "        [0.6685025 ]], dtype=float32)>,\n",
       " 'TE_movieId_rating': <tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       " array([[0.44004914],\n",
       "        [0.8110535 ],\n",
       "        [0.9866613 ],\n",
       "        [0.8503867 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continous_block(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fde086",
   "metadata": {},
   "source": [
    "We connect the continuous block to an `MLPBlock` so as to project them in a higher dimensional space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3af16625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 15:35:34.172673: I tensorflow/stream_executor/cuda/cuda_blas.cc:1792] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_continous_block = continous_block.connect(mm.MLPBlock([64]))\n",
    "deep_continous_block(batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9273fa9",
   "metadata": {},
   "source": [
    "We define the categorical embedding block based on the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb99d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_block = mm.EmbeddingFeatures.from_schema(sub_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40772d06",
   "metadata": {},
   "source": [
    "We visualize the output tensor of the categorical block using data of the first `batch`: it returns the embeddings tensors of categorical features with a default dimension of 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21dbd421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['userId', 'movieId', 'title', 'gender']), TensorShape([4, 64]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embedding_block(batch)\n",
    "embeddings.keys(), embeddings['userId'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae3c83",
   "metadata": {},
   "source": [
    "Let's store the continuous and categorical representations in a single dictionary using `ParallelBlock`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc9e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shapes of DLRM input block:\n",
      "\tuserId : (4, 64)\n",
      "\tmovieId : (4, 64)\n",
      "\ttitle : (4, 64)\n",
      "\tgender : (4, 64)\n",
      "\tcontinuous : (4, 64)\n"
     ]
    }
   ],
   "source": [
    "dlrm_input_block = mm.ParallelBlock({\"embeddings\": embedding_block, \"continuous\": deep_continous_block})\n",
    "print(\"Output shapes of DLRM input block:\")\n",
    "for key, val in dlrm_input_block(batch).items(): \n",
    "    print(\"\\t%s : %s\" %(key, val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b0695",
   "metadata": {},
   "source": [
    "### Build the interaction block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef1489f",
   "metadata": {},
   "source": [
    "Now that we have a vector representation of each input feature, we will create the DLRM interaction block. It consists of three operations: \n",
    "- Apply a dot product between all continous and categorical features to learn pairwise interactions. \n",
    "- Concat the resulting pairwise interaction with the deep representation of conitnuous features. \n",
    "- Apply an `MLPBlock` with a series of layers on the concatenated tensor. \n",
    "\n",
    "The `Block` implements a method `connect_with_shortcut` that connects the input block to other blocks sequentially with a residual connection.\n",
    "\n",
    "#TODO: Add a simple diagram to visualize the residual connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb394acf",
   "metadata": {},
   "source": [
    "First, we will use `connect_with_shortcut` to build the two first operations of DLRM interaction block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48acae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.tf.blocks.dlrm import DotProductInteractionBlock\n",
    "dlrm_interaction = dlrm_input_block.connect_with_shortcut(\n",
    "    DotProductInteractionBlock(), \n",
    "    shortcut_filter=mm.Filter(\"bottom_block\"), \n",
    "    aggregation=\"concat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53b9aff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2016), dtype=float32, numpy=\n",
       "array([[ 0.02296983, -0.01505249, -0.02917415, ...,  0.01208645,\n",
       "         0.02926546,  0.04685134],\n",
       "       [ 0.00456675,  0.01728372, -0.00656997, ...,  0.05093538,\n",
       "         0.04981958,  0.05963509],\n",
       "       [ 0.01007329,  0.02456067, -0.02941924, ...,  0.01750099,\n",
       "         0.04780834,  0.00441987],\n",
       "       [-0.00547133, -0.02438645,  0.03615618, ...,  0.08643801,\n",
       "         0.03780769,  0.01758762]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlrm_interaction(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e9b89a",
   "metadata": {},
   "source": [
    "Then, we project the learned interaction using a series of dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7471ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 512), dtype=float32, numpy=\n",
       "array([[0.00150441, 0.        , 0.        , ..., 0.        , 0.00156314,\n",
       "        0.00148631],\n",
       "       [0.        , 0.00512344, 0.00612389, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.00159896, ..., 0.        , 0.        ,\n",
       "        0.00342017],\n",
       "       [0.00124279, 0.00247318, 0.00704529, ..., 0.        , 0.000864  ,\n",
       "        0.0008056 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_dlrm_interaction = dlrm_interaction.connect(mm.MLPBlock([64, 128, 512]))\n",
    "deep_dlrm_interaction(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f67d43",
   "metadata": {},
   "source": [
    "### Build the Prediction block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f595a",
   "metadata": {},
   "source": [
    "At this stage, we have built the DLRM block that takes as input a dictionary of categorical and continuous tensors and returns the interaction representation vector of shape `512`. The next step is to use this hidden representation to conduct a given prediction task. In our case, we will use the label `rating_binary` and the objective is to: Predict if a user `A` will give a high rating to a movie `B` or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60242582",
   "metadata": {},
   "source": [
    "We will use the `BinaryClassificationTask` and evaluate the performances using `auc` metric. We will also use `LogitsTemperatureScaler` as a pre-transformation Op that scales the logits returned by the task before computing the loss and metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fc92dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.tf.blocks.core.transformations import LogitsTemperatureScaler\n",
    "binary_task = mm.BinaryClassificationTask(\n",
    "    target_name=sub_schema.select_by_tag(Tags.TARGET).column_names[0],\n",
    "    metrics=[tf.keras.metrics.AUC], \n",
    "    pre=LogitsTemperatureScaler(temperature=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff0e585",
   "metadata": {},
   "source": [
    "### Build, train and evaluate the final DLRM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73cfcc",
   "metadata": {},
   "source": [
    "We connect the `deep_dlrm_interaction` to the `binary_task` and the method will automatically  generate the `Model` class for us.\n",
    "We note that the `Model` inherits from [tf.keras.Model](https://keras.io/api/models/model/) class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa4134e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merlin.models.tf.models.base.Model"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deep_dlrm_interaction.connect(binary_task)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ab488",
   "metadata": {},
   "source": [
    "We train the model using Built-in Keras `fit` method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "354fa3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 15:35:34.946572: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding_features/userId:0', 'embedding_features/movieId:0', 'embedding_features/title:0', 'embedding_features/gender:0', 'parallel_block/userId:0', 'parallel_block/movieId:0', 'parallel_block/title:0', 'parallel_block/gender:0', 'sequential_block_7/userId:0', 'sequential_block_7/movieId:0', 'sequential_block_7/title:0', 'sequential_block_7/gender:0', 'sequential_block_9/userId:0', 'sequential_block_9/movieId:0', 'sequential_block_9/title:0', 'sequential_block_9/gender:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding_features/userId:0', 'embedding_features/movieId:0', 'embedding_features/title:0', 'embedding_features/gender:0', 'parallel_block/userId:0', 'parallel_block/movieId:0', 'parallel_block/title:0', 'parallel_block/gender:0', 'sequential_block_7/userId:0', 'sequential_block_7/movieId:0', 'sequential_block_7/title:0', 'sequential_block_7/gender:0', 'sequential_block_9/userId:0', 'sequential_block_9/movieId:0', 'sequential_block_9/title:0', 'sequential_block_9/gender:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding_features/userId:0', 'embedding_features/movieId:0', 'embedding_features/title:0', 'embedding_features/gender:0', 'parallel_block/userId:0', 'parallel_block/movieId:0', 'parallel_block/title:0', 'parallel_block/gender:0', 'sequential_block_7/userId:0', 'sequential_block_7/movieId:0', 'sequential_block_7/title:0', 'sequential_block_7/gender:0', 'sequential_block_9/userId:0', 'sequential_block_9/movieId:0', 'sequential_block_9/title:0', 'sequential_block_9/gender:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding_features/userId:0', 'embedding_features/movieId:0', 'embedding_features/title:0', 'embedding_features/gender:0', 'parallel_block/userId:0', 'parallel_block/movieId:0', 'parallel_block/title:0', 'parallel_block/gender:0', 'sequential_block_7/userId:0', 'sequential_block_7/movieId:0', 'sequential_block_7/title:0', 'sequential_block_7/gender:0', 'sequential_block_9/userId:0', 'sequential_block_9/movieId:0', 'sequential_block_9/title:0', 'sequential_block_9/gender:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 12s 12ms/step - rating_binary/binary_classification_task/auc: 0.5004 - loss: 0.6952 - regularization_loss: 0.0000e+00 - total_loss: 0.6952\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 10s 12ms/step - rating_binary/binary_classification_task/auc: 0.5000 - loss: 0.6931 - regularization_loss: 0.0000e+00 - total_loss: 0.6931\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 10s 12ms/step - rating_binary/binary_classification_task/auc: 0.6714 - loss: 0.6565 - regularization_loss: 0.0000e+00 - total_loss: 0.6565\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 10s 12ms/step - rating_binary/binary_classification_task/auc: 0.7258 - loss: 0.6369 - regularization_loss: 0.0000e+00 - total_loss: 0.6369\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 10s 12ms/step - rating_binary/binary_classification_task/auc: 0.7266 - loss: 0.6330 - regularization_loss: 0.0000e+00 - total_loss: 0.6330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f97b530ecd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\")\n",
    "model.fit(train, batch_size=1024, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36454896",
   "metadata": {},
   "source": [
    "- We get the evaluation scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e1db12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 15:36:27.139613: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: cond/then/_0/cond/cond/branch_executed/_128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 3s 8ms/step - rating_binary/binary_classification_task/auc: 0.7478 - loss: 2.2154 - regularization_loss: 0.0000e+00 - total_loss: 2.2154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rating_binary/binary_classification_task/auc': 0.7477688789367676,\n",
       " 'loss': 2.4032702445983887,\n",
       " 'regularization_loss': 0.0,\n",
       " 'total_loss': 2.4032702445983887}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(valid, batch_size=1024, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dde2c1",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148cebf4",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "#TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
