{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc9663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5804a",
   "metadata": {},
   "source": [
    "## Training a DLRM model with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a978a9a",
   "metadata": {},
   "source": [
    "In the previous notebooks, we have downloaded the movielens data, converted it to parquet files and then used NVTabular library to process the data, join data frames, and create input features. In this notebook we will use NVIDIA Merlin Models library to build and train a Deep Learning Recommendation Model [(DLRM)](https://arxiv.org/abs/1906.00091) architecture originally proposed by Facebook in 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943291ae",
   "metadata": {},
   "source": [
    "Figure 1 illustrates DLRM architecture. The model was introduced as a personalization deep learning model that uses embeddings to process sparse features that represent categorical data and a multilayer perceptron (MLP) to process dense features, then interacts these features explicitly using the statistical techniques proposed in [here](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5694074)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95ddb17",
   "metadata": {},
   "source": [
    "![DLRM](images/DLRM.png)\n",
    "\n",
    "<p>Figure 2.DLRM architecture. Image source: <a href=\"https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Recommendation/DLRM\">Nvidia DL Examples</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da0bb4",
   "metadata": {},
   "source": [
    "DLRM accepts two types of features: categorical and numerical. \n",
    "- For each categorical feature, an embedding table is used to provide dense representation to each unique value. \n",
    "- For numerical features, they are fed to model as dense features, and then transformed by a simple neural network referred to as \"bottom MLP\". This part of the network consists of a series of linear layers with ReLU activations. \n",
    "- The output of the bottom MLP and the embedding vectors are then fed into the `dot product interaction` operation (see Pairwise interaction step). The output of \"dot interaction\" is then concatenated with the features resulting from the bottom MLP (we apply a skip-connection there) and fed into the \"top MLP\" which is also a series of dense layers with activations ((a fully connected NN). \n",
    "- The model outputs a single number (here we use sigmoid function to generate probabilities) which can be interpreted as a likelihood of a certain user clicking on an ad, watching a movie, or viewing a news page. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a725281",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fceff1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nvtabular\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nvtabular as nvt\n",
    "\n",
    "import merlin_models.tf as ml\n",
    "from merlin_standard_lib import Schema, Tag\n",
    "\n",
    "from nvtabular.loader.tensorflow import KerasSequenceLoader\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596ae9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# disable INFO and DEBUG logging everywhere\n",
    "logging.disable(logging.WARNING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e76adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid Numba low occupancy warnings\n",
    "from numba import config\n",
    "config.CUDA_LOW_OCCUPANCY_WARNINGS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f3010",
   "metadata": {},
   "source": [
    "Merlin Models library relies on a `schema` object to automatically build all necessary layers to represent, normalize and aggregate input features. As you can see below, schema.pb is a protobuf file that contains metadata including statistics about features such as cardinality, min and max values and also tags features based on their characteristics and dtypes (e.g., categorical, continuous, list, integer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9917c16",
   "metadata": {},
   "source": [
    "We have already generated our `schema.pbtxt` file in the previous notebook using NVTabular. Not we read this schema file to create a `schema` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c386282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature {\n",
      "  name: \"movieId\"\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    name: \"movieId\"\n",
      "    min: 0\n",
      "    max: 56677\n",
      "    is_categorical: true\n",
      "  }\n",
      "  annotation {\n",
      "    tag: \"item_id\"\n",
      "    tag: \"item\"\n",
      "    tag: \"categorical\"\n",
      "    extra_metadata {\n",
      "      type_url: \"type.googleapis.com/google.protobuf.Struct\"\n",
      "      value: \"\\n\\021\\n\\013num_buckets\\022\\002\\010\\000\\n\\033\\n\\016freq_threshold\\022\\t\\021\\000\\000\\000\\000\\000\\000\\000\\000\\n\\025\\n\\010max_size\\022\\t\\021\\000\\000\\000\\000\\000\\000\\000\\000\\n\\030\\n\\013start_index\\022\\t\\021\\000\\000\\000\\000\\000\\000\\000\\000\\n2\\n\\010cat_path\\022&\\032$.//categories/unique.movieId.parquet\\nG\\n\\017embedding_sizes\\0224*2\\n\\030\\n\\013cardinality\\022\\t\\021\\000\\000\\000\\000\\240\\254\\353@\\n\\026\\n\\tdimension\\022\\t\\021\\000\\000\\000\\000\\000\\000\\200@\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"userId\"\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    name: \"userId\"\n",
      "    min: 0\n",
      "    max: 162542\n",
      "    is_categorical: true\n",
      "  }\n",
      "  annotation {\n",
      "    tag: \"categorical\"\n"
     ]
    }
   ],
   "source": [
    "from merlin_standard_lib import Schema\n",
    "SCHEMA_PATH = \"/workspace/data/movielens/train/schema.pbtxt\"\n",
    "schema = Schema().from_proto_text(SCHEMA_PATH)\n",
    "!head -30 $SCHEMA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df05ad",
   "metadata": {},
   "source": [
    "## Define the Input module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6656c6e",
   "metadata": {},
   "source": [
    "Below we define our input block using the `ml.ContinuousEmbedding` function. The from_schema() method processes the schema and creates the necessary layers to represent features and aggregate them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff81c94",
   "metadata": {},
   "source": [
    "In the next cell, the whole model is build with a few lines of code. Here is a brief explanation of the main classes and functions:\n",
    "\n",
    "- [DotProductInteraction](https://github.com/NVIDIA-Merlin/models/blob/main/merlin_models/tf/layers/interaction.py#L22) class implements the factorization machine style feature interaction layer suggested by the DLRM and DeepFM architectures. Here we do not feed an interaction type, and the `None` interaction type defaults to the standard factorization machine style interaction.\n",
    "- [TabularBlock](https://github.com/NVIDIA-Merlin/models/blob/main/merlin_models/tf/core.py#L661) is a sub-class of `Block` class that accepts dictionary of tensors as inputs and supports the integration of many commonly used operations. This class has additional methods to apply transformations and aggregations to inputs for pre and post processing.\n",
    "- [ParallelBlock](https://github.com/NVIDIA-Merlin/models/blob/main/merlin_models/tf/core.py#L1152) class merges multiple layers or TabularBlock's into a single output of TabularData which is a dictionary of tensors. In this example, this class outputs two parallel layers of continuous and categorical blocks.\n",
    "- [BinaryClassificationTask](https://github.com/NVIDIA-Merlin/models/blob/main/merlin_models/tf/prediction/classification.py#L30) supports the binary prediction task. We also support other predictions tasks, like next-item prediction and regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a613fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_schema = schema.select_by_tag(Tag.CONTINUOUS)\n",
    "cat_schema = schema.select_by_tag(Tag.CATEGORICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45fa5771",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_block_inputs = {}\n",
    "\n",
    "top_block_inputs[\"continuous\"] = ml.ContinuousFeatures.from_schema(con_schema).connect(ml.MLPBlock([128, 64]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8694a",
   "metadata": {},
   "source": [
    "We use ContinousFeatures layer build the dense layer for the continuos features and then we fed this to the MLP layer with `connect` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05d70392",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "top_block_inputs[\"categorical\"] = ml.EmbeddingFeatures.from_schema(\n",
    "    cat_schema, embedding_dim_default=embedding_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f13e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = ml.TabularBlock(aggregation=\"stack\").connect(ml.DotProductInteraction())\n",
    "top_block_outputs = (ml.ParallelBlock(top_block_inputs).connect_with_shortcut\n",
    "                     (\n",
    "                         dot_product, shortcut_filter=ml.Filter(\"continuous\"), aggregation=\"concat\"\n",
    "                     ).connect(ml.MLPBlock([128, 64])\n",
    "                              )\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b47a03fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 23:45:09.832763: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-08 23:45:11.306734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16254 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "model = top_block_outputs.connect(ml.BinaryClassificationTask(\"rating\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758c12e",
   "metadata": {},
   "source": [
    "In addition to this low-level api code, we also have high-level api where you can define a DLRM model with only one line of code as follow:\n",
    "    \n",
    "```\n",
    "ml.DLRMBlock(schema, bottom_block=ml.MLPBlock([128, 64]), top_block=ml.MLPBlock([128, 64])\n",
    "            ).connect(ml.BinaryClassificationTask(\"rating\"))\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6ee22",
   "metadata": {},
   "source": [
    "### Define Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad33ba",
   "metadata": {},
   "source": [
    "We're ready to get trainin.. We'll use the NVTabular `KerasSequenceLoader` for reading chunks of parquet files. `KerasSequenceLoader` manages shuffling by loading in chunks of data from different parts of the full dataset, concatenating them and then shuffling, then iterating through this super-chunk sequentially in batches. The number of \"parts\" of the dataset that get sample, or \"partitions\", is controlled by the `parts_per_chunk` kwarg, while the size of each one of these parts is controlled by the `buffer_size` kwarg, which refers to a fraction of available GPU memory (you can read more about it [here](https://nvidia-merlin.github.io/NVTabular/main/training/tensorflow.html) and [here](https://nvidia-merlin.github.io/NVTabular/main/api/tensorflow_dataloader.html?highlight=kerassequence#nvtabular.loader.tensorflow.KerasSequenceLoader)). Using more chunks leads to better randomness, especially at the epoch level where physically disparate samples can be brought into the same batch, but can impact throughput if you use too many. In any case, the speed of the parquet reader makes feasible buffer sizes much larger.\n",
    "\n",
    "Note that `genres` column is a multi-hot column and it is fed to dataloader as a sparse tensor and then it is converted to dense represantation. Based on our analysis, genres column has max 10 sequence of entries. So we will set the sequence length for the multi-hot columns as 10 in the `sparse_feature_max` dictionary below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66babf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and continuous columns\n",
    "x_cat_names, x_cont_names = ['userId', 'movieId', 'genres'], ['TE_movieId_rating','userId_count']\n",
    "\n",
    "# dictionary representing max sequence length for each column\n",
    "sparse_features_max = {'genres': 10}\n",
    "\n",
    "def get_dataloader(paths_or_dataset, batch_size=4096):\n",
    "    dataloader = KerasSequenceLoader(\n",
    "        paths_or_dataset,\n",
    "        batch_size=batch_size,\n",
    "        label_names=['rating'],\n",
    "        cat_names=x_cat_names,\n",
    "        cont_names=x_cont_names,\n",
    "        sparse_names=list(sparse_features_max.keys()),\n",
    "        sparse_max=sparse_features_max,\n",
    "        sparse_as_dense=True,\n",
    "    )\n",
    "    return dataloader.map(lambda X, y: (X, tf.reshape(y, (-1,))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf52de3",
   "metadata": {},
   "source": [
    "### Start Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95706913",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"/workspace/data/movielens/\")\n",
    "train_paths = glob.glob(os.path.join(OUTPUT_DIR, \"train/*.parquet\"))\n",
    "eval_paths = glob.glob(os.path.join(OUTPUT_DIR, \"valid/*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f23b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", run_eagerly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8a467bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Launch training\n",
      "********************\n",
      "\n",
      "WARNING: AutoGraph could not transform <bound method Block.parse of <class 'merlin_models.tf.core.Block'>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: annotated name 'output' can't be nonlocal (tmpn84hxazp.py, line 36)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 23:45:26.273241: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4883/4883 [==============================] - 179s 34ms/step - rating/binary_classification_task/precision: 0.7625 - rating/binary_classification_task/recall: 0.8614 - rating/binary_classification_task/binary_accuracy: 0.7456 - rating/binary_classification_task/auc: 0.8023 - loss: 0.5138 - regularization_loss: 0.0000e+00 - total_loss: 0.5138\n",
      "Epoch 2/3\n",
      "4883/4883 [==============================] - 172s 34ms/step - rating/binary_classification_task/precision: 0.7802 - rating/binary_classification_task/recall: 0.8633 - rating/binary_classification_task/binary_accuracy: 0.7625 - rating/binary_classification_task/auc: 0.8276 - loss: 0.4851 - regularization_loss: 0.0000e+00 - total_loss: 0.4851\n",
      "Epoch 3/3\n",
      "4883/4883 [==============================] - 173s 34ms/step - rating/binary_classification_task/precision: 0.7899 - rating/binary_classification_task/recall: 0.8659 - rating/binary_classification_task/binary_accuracy: 0.7721 - rating/binary_classification_task/auc: 0.8406 - loss: 0.4689 - regularization_loss: 0.0000e+00 - total_loss: 0.4689\n",
      "********************\n",
      "Start evaluation\n",
      "1221/1221 [==============================] - 45s 27ms/step - rating/binary_classification_task/precision: 0.7840 - rating/binary_classification_task/recall: 0.8561 - rating/binary_classification_task/binary_accuracy: 0.7626 - rating/binary_classification_task/auc: 0.8262 - loss: 0.4885 - regularization_loss: 0.0000e+00 - total_loss: 0.4885\n",
      "********************\n",
      "Eval results\n",
      "\n",
      "********************\n",
      "\n",
      " loss = 0.472271203994751\n",
      " rating/binary_classification_task/auc = 0.8262367248535156\n",
      " rating/binary_classification_task/binary_accuracy = 0.762577474117279\n",
      " rating/binary_classification_task/precision = 0.7839897871017456\n",
      " rating/binary_classification_task/recall = 0.856126070022583\n",
      " regularization_loss = 0\n",
      " total_loss = 0.472271203994751\n"
     ]
    }
   ],
   "source": [
    "print('*'*20)\n",
    "print(\"Launch training\")\n",
    "print('*'*20 + '\\n')\n",
    "train_loader = get_dataloader(train_paths) \n",
    "losses = model.fit(train_loader, epochs=3)\n",
    "model.reset_metrics()\n",
    "\n",
    "# Evaluate\n",
    "print('*'*20)\n",
    "print(\"Start evaluation\")\n",
    "eval_loader = get_dataloader(eval_paths) \n",
    "eval_metrics = model.evaluate(eval_loader, return_dict=True)\n",
    "\n",
    "print('*'*20)\n",
    "print(\"Eval results\")\n",
    "print('\\n' + '*'*20 + '\\n')\n",
    "for key in sorted(eval_metrics.keys()):\n",
    "    print(\" %s = %s\" % (key, str(eval_metrics[key]))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f6d22",
   "metadata": {},
   "source": [
    "### Perform Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c5033c",
   "metadata": {},
   "source": [
    "Let's use validation set and perform prediction for a given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "944887e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_parquet(\"/workspace/data/movielens/valid/part_0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46f90e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "      <th>TE_movieId_rating</th>\n",
       "      <th>userId_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1207</td>\n",
       "      <td>69789</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.869776</td>\n",
       "      <td>1.66064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484</td>\n",
       "      <td>69789</td>\n",
       "      <td>[2, 12]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475380</td>\n",
       "      <td>1.66064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>574</td>\n",
       "      <td>69789</td>\n",
       "      <td>[2, 8, 1, 16]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.717452</td>\n",
       "      <td>1.66064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91</td>\n",
       "      <td>69789</td>\n",
       "      <td>[3, 5, 7, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.702393</td>\n",
       "      <td>1.66064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>517</td>\n",
       "      <td>69789</td>\n",
       "      <td>[11, 6, 7, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680634</td>\n",
       "      <td>1.66064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  userId         genres  rating  TE_movieId_rating  userId_count\n",
       "0     1207   69789         [1, 4]       0           0.869776       1.66064\n",
       "1      484   69789        [2, 12]       1           0.475380       1.66064\n",
       "2      574   69789  [2, 8, 1, 16]       1           0.717452       1.66064\n",
       "3       91   69789   [3, 5, 7, 4]       0           0.702393       1.66064\n",
       "4      517   69789  [11, 6, 7, 4]       0           0.680634       1.66064"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = valid[valid['userId']==69789].reset_index(drop=True)\n",
    "batch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e74ce",
   "metadata": {},
   "source": [
    "We first need to pad the genres column to be able to create a dictionary of tensors to serve as input to `model.predict()`. We could also use NVTabular `ListSlice` op for that but since we will only process couple of lines we can do that with a function defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b486f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(s, seq_length=10):\n",
    "    padding_len = seq_length - len(s)\n",
    "    padded = np.pad(s, (0, padding_len), 'constant', constant_values=(0))\n",
    "    return padded\n",
    "\n",
    "padded_genres = batch['genres'].apply(padding)\n",
    "batch.loc[:,'genres'] = padded_genres.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee221c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our dataframe to a dictionary of tensors\n",
    "def tf_tensor_dict(df):\n",
    "    import tensorflow as tf\n",
    "\n",
    "    data = df.to_dict(\"list\")\n",
    "\n",
    "    return {key: tf.convert_to_tensor(value) for key, value in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f446fc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movieId': <tf.Tensor: shape=(22,), dtype=int32, numpy=\n",
       " array([1207,  484,  574,   91,  517,  221,   80,  205,  125,  808,  104,\n",
       "         630,  331,    1,  486,  192,  307,  292,  129,  413, 1294,  526],\n",
       "       dtype=int32)>,\n",
       " 'userId': <tf.Tensor: shape=(22,), dtype=int32, numpy=\n",
       " array([69789, 69789, 69789, 69789, 69789, 69789, 69789, 69789, 69789,\n",
       "        69789, 69789, 69789, 69789, 69789, 69789, 69789, 69789, 69789,\n",
       "        69789, 69789, 69789, 69789], dtype=int32)>,\n",
       " 'genres': <tf.Tensor: shape=(22, 10), dtype=int32, numpy=\n",
       " array([[ 1,  4,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2, 12,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2,  8,  1, 16,  0,  0,  0,  0,  0,  0],\n",
       "        [ 3,  5,  7,  4,  0,  0,  0,  0,  0,  0],\n",
       "        [11,  6,  7,  4,  0,  0,  0,  0,  0,  0],\n",
       "        [ 5,  2,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  6,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 3,  5,  7,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 3,  8,  1, 11,  4,  0,  0,  0,  0,  0],\n",
       "        [ 8,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2,  6,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 8,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 8,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 3,  5,  4,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 3,  4,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2,  6,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 3,  1,  4,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 2,  1,  6,  0,  0,  0,  0,  0,  0,  0]], dtype=int32)>,\n",
       " 'rating': <tf.Tensor: shape=(22,), dtype=int32, numpy=\n",
       " array([0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "       dtype=int32)>,\n",
       " 'TE_movieId_rating': <tf.Tensor: shape=(22,), dtype=float32, numpy=\n",
       " array([0.8697765 , 0.47538006, 0.7174522 , 0.7023928 , 0.68063414,\n",
       "        0.8176361 , 0.84984684, 0.809332  , 0.80828744, 0.8056389 ,\n",
       "        0.83617544, 0.7963735 , 0.696779  , 0.9832551 , 0.78700113,\n",
       "        0.80491185, 0.7303669 , 0.7918506 , 0.7592673 , 0.676067  ,\n",
       "        0.7403009 , 0.7535586 ], dtype=float32)>,\n",
       " 'userId_count': <tf.Tensor: shape=(22,), dtype=float32, numpy=\n",
       " array([1.6606405, 1.6606405, 1.6606405, 1.6606405, 1.6606405, 1.6606405,\n",
       "        1.6606405, 1.6606405, 1.6606405, 1.6606405, 1.6606405, 1.6606405,\n",
       "        1.6606405, 1.6606405, 1.6606405, 1.6606405, 1.6606405, 1.6606405,\n",
       "        1.6606405, 1.6606405, 1.6606405, 1.6606405], dtype=float32)>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tensor = tf_tensor_dict(batch)\n",
    "batch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a28c1558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52605325],\n",
       "       [0.17234999],\n",
       "       [0.45934787],\n",
       "       [0.3444392 ],\n",
       "       [0.29376656],\n",
       "       [0.33181232],\n",
       "       [0.67826164],\n",
       "       [0.49523795],\n",
       "       [0.5502221 ],\n",
       "       [0.64141977],\n",
       "       [0.70937765],\n",
       "       [0.8737097 ],\n",
       "       [0.37274352],\n",
       "       [0.8956236 ],\n",
       "       [0.5559566 ],\n",
       "       [0.49068797],\n",
       "       [0.6118884 ],\n",
       "       [0.1779553 ],\n",
       "       [0.61409414],\n",
       "       [0.6127957 ],\n",
       "       [0.7583447 ],\n",
       "       [0.47995976]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform prediction for userId 69789\n",
    "predictions = model.predict(batch_tensor)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15c499",
   "metadata": {},
   "source": [
    "The predictions are probabilities that shows the likelihood of a user liking a movie or not. What's the movie that the user `69789` will like most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d823ea51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>69789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieId  userId\n",
       "13        1   69789"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['predict_proba'] = predictions\n",
    "\n",
    "# select the row where the estimated probability is highest\n",
    "batch[batch['predict_proba']==batch['predict_proba'].max()][['movieId', 'userId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ce80a",
   "metadata": {},
   "source": [
    "Based on the estimated probabilities, we can say that the  `69789` would like the movie `1` most with probability of `0.8956236`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
