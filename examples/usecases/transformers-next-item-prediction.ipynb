{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a556f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions anda\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa80126e",
   "metadata": {},
   "source": [
    "Run the below cell once in a new TF 22.09 container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42ab59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# cd /models && git pull && pip install .\n",
    "# cd /nvtabular && git pull && pip install .\n",
    "# cd /core && git pull && pip install .\n",
    "# cd /systems && git pull && pip install .\n",
    "\n",
    "# pip install tensorflow\n",
    "# pip install transformers==4.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1edd3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I do not need this on my machine, but can be helpful if you encounter issues\n",
    "\n",
    "# import os\n",
    "# os.environ[\"FORCE_TF_AVAILABLE\"]=\"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697d1452",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_models_entertainment-with-pretrained-embeddings/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Transformer-based architecture for next-item prediction task\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this use case we will train a Transformer-based architecture for next-item prediction task.\n",
    "\n",
    "We will use the [booking.com dataset](https://github.com/bookingcom/ml-dataset-mdt) to train a session-based model. The dataset contains 1,166,835 of anonymized hotel reservations in the train set and 378,667 in the test set. Each reservation is a part of a customer's trip (identified by `utrip_id`) which includes consecutive reservations.\n",
    "\n",
    "We will reshape the data to organize it into 'sessions'. Each session will be a full customer itinerary in chronological order. The goal will be to predict the city_id of the final reservation of each trip.\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "- Training a Transformer-based architecture for next-item prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cccd005",
   "metadata": {},
   "source": [
    "## Downloading and preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0b619b",
   "metadata": {},
   "source": [
    "You can download the full dataset from GitHub [here](https://github.com/bookingcom/ml-dataset-mdt). Please place it alognside this notebook (or alternatively, change the `DATAPATH` to point to where it is located)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d9dccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.core.dispatch import get_lib\n",
    "import numpy as np\n",
    "\n",
    "DATAPATH = 'ml-dataset-mdt'\n",
    "\n",
    "itineraries = get_lib().read_csv(f'{DATAPATH}/train_set.csv', parse_dates=['checkin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b7224",
   "metadata": {},
   "source": [
    "Each reservation has a unique `utrip_id`. During each trip a customer vists several destinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192a5727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>city_id</th>\n",
       "      <th>device_class</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>booker_country</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>utrip_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>8183</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7168</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-14</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>15626</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7168</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>2016-08-18</td>\n",
       "      <td>60902</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7168</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000027</td>\n",
       "      <td>2016-08-18</td>\n",
       "      <td>2016-08-21</td>\n",
       "      <td>30628</td>\n",
       "      <td>desktop</td>\n",
       "      <td>253</td>\n",
       "      <td>Elbonia</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>1000027_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000033</td>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>38677</td>\n",
       "      <td>mobile</td>\n",
       "      <td>359</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Cobra Island</td>\n",
       "      <td>1000033_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    checkin    checkout  city_id device_class  affiliate_id  \\\n",
       "0  1000027 2016-08-13  2016-08-14     8183      desktop          7168   \n",
       "1  1000027 2016-08-14  2016-08-16    15626      desktop          7168   \n",
       "2  1000027 2016-08-16  2016-08-18    60902      desktop          7168   \n",
       "3  1000027 2016-08-18  2016-08-21    30628      desktop           253   \n",
       "4  1000033 2016-04-09  2016-04-11    38677       mobile           359   \n",
       "\n",
       "  booker_country hotel_country   utrip_id  \n",
       "0        Elbonia        Gondal  1000027_1  \n",
       "1        Elbonia        Gondal  1000027_1  \n",
       "2        Elbonia        Gondal  1000027_1  \n",
       "3        Elbonia        Gondal  1000027_1  \n",
       "4         Gondal  Cobra Island  1000033_1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itineraries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554eb309",
   "metadata": {},
   "source": [
    "We will limit the sequence length to between 2 and 10 trips. That will capture upwards of 95% datapoints!\n",
    "\n",
    "We don't want to train on trips that are shorter than two hops -- our model would not be able to learn much from such sequences. Additionally, such short sequences are uncharacteristically short for this dataset.\n",
    "\n",
    "Besides, training on unusually long or short sequences, that are far outside of the most common sequence length, might not be the best use of our compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346b871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TRIP_LENGTH = 10\n",
    "MIN_TRIP_LENGTH = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0702c",
   "metadata": {},
   "source": [
    "Let us now split the data into a train and validation set based on trip ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05b2c1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217686"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utrip_ids = itineraries.utrip_id.unique().sample(frac=1)\n",
    "len(utrip_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7754847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_utrip_ids = utrip_ids[:160_000]\n",
    "validation_set_utrip_ids = utrip_ids[160_000:]\n",
    "\n",
    "train_set = itineraries[itineraries.utrip_id.isin(train_set_utrip_ids)]\n",
    "validation_set = itineraries[itineraries.utrip_id.isin(validation_set_utrip_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc3992",
   "metadata": {},
   "source": [
    "We can now begin with data preprocessing.\n",
    "\n",
    "We will combine trips into \"sessions\", discard trips that are either too short or too long and calculate total trip length in stops.\n",
    "\n",
    "We will use nvtabular for this work. It offers optimized tabular data preprocessing operators that run on the GPU. If you would like to learn more about this software library, please take a look [here](https://github.com/NVIDIA-Merlin/NVTabular)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ec166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 12:51:01.441597: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-03 12:51:01.542220: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-03 12:51:02.092005: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/hugectr/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/lib:/repos/dist/lib:/opt/tritonserver/lib\n",
      "2022-11-03 12:51:02.092064: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/hugectr/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/lib:/repos/dist/lib:/opt/tritonserver/lib\n",
      "2022-11-03 12:51:02.092069: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 12:51:02.586870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 12:51:02.587368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 12:51:02.587528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 12:51:02.609677: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-03 12:51:02.611021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 12:51:02.611208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 12:51:02.611343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 12:51:02.902758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 12:51:02.902944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 12:51:02.903080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-03 12:51:02.903208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24576 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:08:00.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from nvtabular import *\n",
    "from nvtabular import ops\n",
    "from merlin.models.tf import Loader\n",
    "\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3435af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_dataset = Dataset(train_set)\n",
    "validation_set_dataset = Dataset(validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60bd5e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_features = ['city_id', 'booker_country', 'utrip_id', 'checkin'] >> ops.Groupby(\n",
    "    groupby_cols=['utrip_id'],\n",
    "    sort_cols=['checkin'],\n",
    "    aggs={\n",
    "        'city_id': ['list', 'count'],\n",
    "        'booker_country': ['list']\n",
    "    }\n",
    ")\n",
    "\n",
    "groupby_features_truncated_city = groupby_features['city_id_list'] >> ops.Categorify() >> ops.ListSlice(0, MAX_TRIP_LENGTH, pad=True) >> ops.AddTags([Tags.SEQUENCE, Tags.ITEM, Tags.ITEM_ID])\n",
    "groupby_features_truncated_country = groupby_features['booker_country_list'] >> ops.Categorify() >> ops.ListSlice(0, MAX_TRIP_LENGTH, pad=True) >> ops.AddTags([Tags.SEQUENCE, Tags.ITEM])\n",
    "city_id_count = groupby_features['city_id_count'] >> ops.AddTags([Tags.CONTEXT, Tags.ITEM, Tags.CONTINUOUS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6105767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(groupby_features_truncated_city + groupby_features_truncated_country + city_id_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edcbcdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/cudf/core/frame.py:384: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/cudf/core/frame.py:384: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_set_processed = wf.fit_transform(train_set_dataset)\n",
    "validation_set_processed = wf.fit_transform(validation_set_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a6675",
   "metadata": {},
   "source": [
    "Our data consists of a sequence of visited `city_ids`, a sequence of `booker_countries` (represented as integer categories) and a `city_id_count` column (which contains the count of visited cities in a trip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dee6b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id_list</th>\n",
       "      <th>booker_country_list</th>\n",
       "      <th>city_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[62, 1295, 86, 652, 62, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7, 6, 21, 980, 57, 55, 3, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4479, 241, 508, 237, 359, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 370, 292, 527, 309, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[52, 112, 800, 130, 157, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 0, 0, 0, 0, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                city_id_list             booker_country_list  \\\n",
       "0     [62, 1295, 86, 652, 62, 0, 0, 0, 0, 0]  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]   \n",
       "1        [7, 6, 21, 980, 57, 55, 3, 0, 0, 0]  [2, 2, 2, 2, 2, 2, 2, 0, 0, 0]   \n",
       "2  [4479, 241, 508, 237, 359, 0, 0, 0, 0, 0]  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]   \n",
       "3     [1, 370, 292, 527, 309, 0, 0, 0, 0, 0]  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]   \n",
       "4    [52, 112, 800, 130, 157, 0, 0, 0, 0, 0]  [2, 2, 2, 2, 2, 0, 0, 0, 0, 0]   \n",
       "\n",
       "   city_id_count  \n",
       "0              5  \n",
       "1              7  \n",
       "2              5  \n",
       "3              5  \n",
       "4              5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_processed.compute().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89cc3a0",
   "metadata": {},
   "source": [
    "We are now ready to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7ee9923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import merlin.models.tf as mm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95c794",
   "metadata": {},
   "source": [
    "Let's identify two schemas. The first one for sequential features, the other for context features (`city_id_count`) that we will broadcast to the entire sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4813456",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_schema = train_set_processed.schema.select_by_tag(Tags.SEQUENCE)\n",
    "context_schema = train_set_processed.schema.select_by_tag(Tags.CONTEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d422833",
   "metadata": {},
   "source": [
    "Let's also identify the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e34a3a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_set_processed.schema.select_by_tag(Tags.SEQUENCE).column_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7ce10e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:148: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id_list</th>\n",
       "      <th>booker_country_list</th>\n",
       "      <th>city_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[62, 1295, 86, 652, 62, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7, 6, 21, 980, 57, 55, 3, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4479, 241, 508, 237, 359, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 370, 292, 527, 309, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[52, 112, 800, 130, 157, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 2, 0, 0, 0, 0, 0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>[234, 126, 7, 21, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>[129, 972, 129, 129, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>[95, 86, 95, 61, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[2, 2, 2, 2, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>[66, 335, 828, 335, 1294, 459, 9951, 1283, 253...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>[2103, 21311, 10166, 4000, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             city_id_list  \\\n",
       "0                  [62, 1295, 86, 652, 62, 0, 0, 0, 0, 0]   \n",
       "1                     [7, 6, 21, 980, 57, 55, 3, 0, 0, 0]   \n",
       "2               [4479, 241, 508, 237, 359, 0, 0, 0, 0, 0]   \n",
       "3                  [1, 370, 292, 527, 309, 0, 0, 0, 0, 0]   \n",
       "4                 [52, 112, 800, 130, 157, 0, 0, 0, 0, 0]   \n",
       "...                                                   ...   \n",
       "159995                [234, 126, 7, 21, 0, 0, 0, 0, 0, 0]   \n",
       "159996             [129, 972, 129, 129, 0, 0, 0, 0, 0, 0]   \n",
       "159997                 [95, 86, 95, 61, 0, 0, 0, 0, 0, 0]   \n",
       "159998  [66, 335, 828, 335, 1294, 459, 9951, 1283, 253...   \n",
       "159999       [2103, 21311, 10166, 4000, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                   booker_country_list  city_id_count  \n",
       "0       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]              5  \n",
       "1       [2, 2, 2, 2, 2, 2, 2, 0, 0, 0]              7  \n",
       "2       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]              5  \n",
       "3       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]              5  \n",
       "4       [2, 2, 2, 2, 2, 0, 0, 0, 0, 0]              5  \n",
       "...                                ...            ...  \n",
       "159995  [2, 2, 2, 2, 0, 0, 0, 0, 0, 0]              4  \n",
       "159996  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]              4  \n",
       "159997  [2, 2, 2, 2, 0, 0, 0, 0, 0, 0]              4  \n",
       "159998  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]             15  \n",
       "159999  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]              4  \n",
       "\n",
       "[160000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_processed.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0d0224d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_id_list</td>\n",
       "      <td>(Tags.ID, Tags.CATEGORICAL, Tags.LIST, Tags.IT...</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>.//categories/unique.city_id_list.parquet</td>\n",
       "      <td>0</td>\n",
       "      <td>36071</td>\n",
       "      <td>city_id_list</td>\n",
       "      <td>36072</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>booker_country_list</td>\n",
       "      <td>(Tags.ITEM, Tags.LIST, Tags.SEQUENCE, Tags.CAT...</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>.//categories/unique.booker_country_list.parquet</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>booker_country_list</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'city_id_list', 'tags': {<Tags.ID: 'id'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.city_id_list.parquet', 'domain': {'min': 0, 'max': 36071, 'name': 'city_id_list'}, 'embedding_sizes': {'cardinality': 36072, 'dimension': 512}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': True}, {'name': 'booker_country_list', 'tags': {<Tags.ITEM: 'item'>, <Tags.LIST: 'list'>, <Tags.SEQUENCE: 'sequence'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.booker_country_list.parquet', 'domain': {'min': 0, 'max': 5, 'name': 'booker_country_list'}, 'embedding_sizes': {'cardinality': 6, 'dimension': 16}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_processed.schema.select_by_tag(Tags.SEQUENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a12009aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_id_count</td>\n",
       "      <td>(Tags.ITEM, Tags.CONTINUOUS, Tags.CONTEXT)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'city_id_count', 'tags': {<Tags.ITEM: 'item'>, <Tags.CONTINUOUS: 'continuous'>, <Tags.CONTEXT: 'context'>}, 'properties': {}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_processed.schema.select_by_tag(Tags.CONTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cddfd424",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = Loader(train_set_processed, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbcbcef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06e3c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.tf.transforms.features import BroadcastToSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2969bf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_id_count</td>\n",
       "      <td>(Tags.ITEM, Tags.CONTINUOUS, Tags.CONTEXT)</td>\n",
       "      <td>int32</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'city_id_count', 'tags': {<Tags.ITEM: 'item'>, <Tags.CONTINUOUS: 'continuous'>, <Tags.CONTEXT: 'context'>}, 'properties': {}, 'dtype': dtype('int32'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdb4e34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_id_list</td>\n",
       "      <td>(Tags.ID, Tags.CATEGORICAL, Tags.LIST, Tags.IT...</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>.//categories/unique.city_id_list.parquet</td>\n",
       "      <td>0</td>\n",
       "      <td>36071</td>\n",
       "      <td>city_id_list</td>\n",
       "      <td>36072</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>booker_country_list</td>\n",
       "      <td>(Tags.ITEM, Tags.LIST, Tags.SEQUENCE, Tags.CAT...</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>.//categories/unique.booker_country_list.parquet</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>booker_country_list</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'city_id_list', 'tags': {<Tags.ID: 'id'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>, <Tags.SEQUENCE: 'sequence'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.city_id_list.parquet', 'domain': {'min': 0, 'max': 36071, 'name': 'city_id_list'}, 'embedding_sizes': {'cardinality': 36072, 'dimension': 512}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': True}, {'name': 'booker_country_list', 'tags': {<Tags.ITEM: 'item'>, <Tags.LIST: 'list'>, <Tags.SEQUENCE: 'sequence'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'start_index': 0, 'cat_path': './/categories/unique.booker_country_list.parquet', 'domain': {'min': 0, 'max': 5, 'name': 'booker_country_list'}, 'embedding_sizes': {'cardinality': 6, 'dimension': 16}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b1bc6",
   "metadata": {},
   "source": [
    "## Specifying correct input_dimensions (before broadcasting) in model constructor (d_model=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e65e8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17feb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = mm.InputBlockV2(\n",
    "    train_set_processed.schema,\n",
    "    embeddings=mm.Embeddings(\n",
    "        train_set_processed.schema.select_by_tag(Tags.CATEGORICAL), sequence_combiner=None\n",
    "    ),\n",
    "    post=BroadcastToSequence(context_schema, seq_schema)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bd8fb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1024, None, 41])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer(batch[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95ff6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mm.MLPBlock([41, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95e5907e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1024, None, 40])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp(input_layer(batch[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caf216b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mm.Model(\n",
    "    mm.InputBlockV2(\n",
    "        train_set_processed.schema,\n",
    "        embeddings=mm.Embeddings(\n",
    "            train_set_processed.schema.select_by_tag(Tags.CATEGORICAL), sequence_combiner=None\n",
    "        ),\n",
    "        post=BroadcastToSequence(context_schema, seq_schema)\n",
    "    ),\n",
    "    mm.MLPBlock([41, 40]),\n",
    "    mm.GPT2Block(d_model=40, n_head=4, n_layer=2, pre=mm.ReplaceMaskedEmbeddings()),\n",
    "    mm.CategoricalOutput(\n",
    "        train_set_processed.schema.select_by_name(target),\n",
    "        default_loss=\"categorical_crossentropy\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96f16fdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequence_mask_random_1\" \"                 f\"(type SequenceMaskRandom).\n\nThe sequential inputs must have the same shape, but the shapesare different: {'city_id_list': [1024, None], 'booker_country_list': [1024, None], 'city_id_count': [1024, 1]}\n\nCall arguments received by layer \"sequence_mask_random_1\" \"                 f\"(type SequenceMaskRandom):\n  • inputs={'city_id_list': '<tf.RaggedTensor [[811, 59, 89, ..., 0, 0, 0],\\n [20985, 7330, 15018, ..., 0, 5997, 13485],\\n [139, 139, 129, ..., 0, 0, 0],\\n ...,\\n [15, 1148, 15, ..., 0, 0, 0],\\n [4838, 115, 770, ..., 0, 0, 0],\\n [1060, 338, 491, ..., 0, 0, 0]]>', 'booker_country_list': '<tf.RaggedTensor [[1, 1, 1, ..., 0, 0, 0],\\n [3, 3, 3, ..., 3, 3, 3],\\n [2, 2, 2, ..., 0, 0, 0],\\n ...,\\n [2, 2, 2, ..., 0, 0, 0],\\n [3, 3, 3, ..., 0, 0, 0],\\n [2, 2, 2, ..., 0, 0, 0]]>', 'city_id_count': 'tf.Tensor(shape=(1024, 1), dtype=int32)'}\n  • targets=None\n  • training=True\n  • testing=False\n  • kwargs={'features': {'city_id_list': ('tf.Tensor(shape=(10240, 1), dtype=int64)', 'tf.Tensor(shape=(1024, 1), dtype=int32)'), 'booker_country_list': ('tf.Tensor(shape=(10240, 1), dtype=int64)', 'tf.Tensor(shape=(1024, 1), dtype=int32)'), 'city_id_count': 'tf.Tensor(shape=(1024, 1), dtype=int32)'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(run_eagerly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequenceMaskRandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set_processed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasking_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/models/base.py:856\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, train_metrics_steps, pre, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_compile_cache()\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_pre \u001b[38;5;241m=\u001b[39m pre\n\u001b[0;32m--> 856\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre:\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_pre\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/models/base.py:671\u001b[0m, in \u001b[0;36mBaseModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    668\u001b[0m x, y, sample_weight \u001b[38;5;241m=\u001b[39m unpack_x_y_sample_weight(data)\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_pre\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 671\u001b[0m     out \u001b[38;5;241m=\u001b[39m call_layer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_pre, x, targets\u001b[38;5;241m=\u001b[39my, features\u001b[38;5;241m=\u001b[39mx, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, Prediction):\n\u001b[1;32m    673\u001b[0m         x, y \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moutputs, out\u001b[38;5;241m.\u001b[39mtargets\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/utils/tf_utils.py:437\u001b[0m, in \u001b[0;36mcall_layer\u001b[0;34m(layer, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m         call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(layer)\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m    435\u001b[0m         filtered_kwargs \u001b[38;5;241m=\u001b[39m filter_kwargs(filtered_kwargs, call_fn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_k)\n\u001b[0;32m--> 437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfiltered_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/core/tabular.py:478\u001b[0m, in \u001b[0;36m_tabular_call\u001b[0;34m(self, inputs, pre, post, merge_with, aggregation, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_call(inputs, transformations\u001b[38;5;241m=\u001b[39mpre)\n\u001b[1;32m    477\u001b[0m \u001b[38;5;66;03m# This will call the `call` method implemented by the super class.\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    481\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_call(\n\u001b[1;32m    482\u001b[0m         outputs, transformations\u001b[38;5;241m=\u001b[39mpost, merge_with\u001b[38;5;241m=\u001b[39mmerge_with, aggregation\u001b[38;5;241m=\u001b[39maggregation\n\u001b[1;32m    483\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/config/schema.py:58\u001b[0m, in \u001b[0;36mSchemaMixin.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_schema()\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/transforms/sequence.py:377\u001b[0m, in \u001b[0;36mSequenceTargetAsInput.call\u001b[0;34m(self, inputs, targets, training, testing, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m, inputs: TabularData, targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, testing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    376\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Prediction:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_seq_inputs_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m     new_target \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39midentity(inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_name])\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/merlin/models/tf/transforms/sequence.py:160\u001b[0m, in \u001b[0;36mSequenceTransform._check_seq_inputs_targets\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    158\u001b[0m seq_shapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(seq_inputs_shapes\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(x \u001b[38;5;241m==\u001b[39m seq_shapes[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m seq_shapes):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe sequential inputs must have the same shape, but the shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare different: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_inputs_shapes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"sequence_mask_random_1\" \"                 f\"(type SequenceMaskRandom).\n\nThe sequential inputs must have the same shape, but the shapesare different: {'city_id_list': [1024, None], 'booker_country_list': [1024, None], 'city_id_count': [1024, 1]}\n\nCall arguments received by layer \"sequence_mask_random_1\" \"                 f\"(type SequenceMaskRandom):\n  • inputs={'city_id_list': '<tf.RaggedTensor [[811, 59, 89, ..., 0, 0, 0],\\n [20985, 7330, 15018, ..., 0, 5997, 13485],\\n [139, 139, 129, ..., 0, 0, 0],\\n ...,\\n [15, 1148, 15, ..., 0, 0, 0],\\n [4838, 115, 770, ..., 0, 0, 0],\\n [1060, 338, 491, ..., 0, 0, 0]]>', 'booker_country_list': '<tf.RaggedTensor [[1, 1, 1, ..., 0, 0, 0],\\n [3, 3, 3, ..., 3, 3, 3],\\n [2, 2, 2, ..., 0, 0, 0],\\n ...,\\n [2, 2, 2, ..., 0, 0, 0],\\n [3, 3, 3, ..., 0, 0, 0],\\n [2, 2, 2, ..., 0, 0, 0]]>', 'city_id_count': 'tf.Tensor(shape=(1024, 1), dtype=int32)'}\n  • targets=None\n  • training=True\n  • testing=False\n  • kwargs={'features': {'city_id_list': ('tf.Tensor(shape=(10240, 1), dtype=int64)', 'tf.Tensor(shape=(1024, 1), dtype=int32)'), 'booker_country_list': ('tf.Tensor(shape=(10240, 1), dtype=int64)', 'tf.Tensor(shape=(1024, 1), dtype=int32)'), 'city_id_count': 'tf.Tensor(shape=(1024, 1), dtype=int32)'}}"
     ]
    }
   ],
   "source": [
    "model.compile(run_eagerly=True, optimizer='adam', loss=\"categorical_crossentropy\")\n",
    "model.fit(loader, pre=mm.SequenceMaskRandom(schema=train_set_processed.schema, target=target, masking_prob=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c662af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first stab at evaluation\n",
    "\n",
    "loader_eval = Loader(validation_set_processed, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(loader_eval, batch_size=1024, pre=mm.SequenceMaskLast(schema=train_set_processed.schema, target=target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
